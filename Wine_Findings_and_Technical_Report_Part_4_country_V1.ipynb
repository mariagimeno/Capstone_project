{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE - FINDINGS AND TECHNICAL REPORT WINE BLIND TASTING (COUNTRY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have built a classification model that, based on a wine description given by an expert or semi-expert, is able to tell what country was used to produce that wine. The small dataset contains 42 differents countries and the big data set contains 43 countries. I have included Washington and California as a country for the big representation of this wines in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pd.set_option('display.max_columns',500)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMALL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('small_wineV1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Buxom and heady, this is a delightfully rich, ...</td>\n",
       "      <td>Vieilles Vignes</td>\n",
       "      <td>99</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Châteauneuf-du-Pape</td>\n",
       "      <td>Rhône Valley</td>\n",
       "      <td>Anna Lee C. Iijima</td>\n",
       "      <td>Domaine de la Janasse 2016 Vieilles Vignes Red...</td>\n",
       "      <td>Rhône-style Red Blend</td>\n",
       "      <td>Domaine de la Janasse</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>Sultry and silken on the palate, this wine sta...</td>\n",
       "      <td>La Réserve</td>\n",
       "      <td>98</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Châteauneuf-du-Pape</td>\n",
       "      <td>Rhône Valley</td>\n",
       "      <td>Anna Lee C. Iijima</td>\n",
       "      <td>Domaine le Clos du Caillou 2016 La Réserve Red...</td>\n",
       "      <td>Rhône-style Red Blend</td>\n",
       "      <td>Domaine le Clos du Caillou</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>The wine's fine perfumed black plum fruits giv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Port</td>\n",
       "      <td>Port Blend</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Fonseca 2017  Port</td>\n",
       "      <td>Port</td>\n",
       "      <td>Fonseca</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>Veins of vanilla, smoke and toast amplify blac...</td>\n",
       "      <td>Hommage à Henry Tacussel</td>\n",
       "      <td>98</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Châteauneuf-du-Pape</td>\n",
       "      <td>Rhône Valley</td>\n",
       "      <td>Anna Lee C. Iijima</td>\n",
       "      <td>Domaine Moulin-Tacussel 2016 Hommage à Henry T...</td>\n",
       "      <td>Grenache</td>\n",
       "      <td>Domaine Moulin-Tacussel</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This juicy, fruit-forward wine drenches the pa...</td>\n",
       "      <td>La Muse</td>\n",
       "      <td>97</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Châteauneuf-du-Pape</td>\n",
       "      <td>Rhône Valley</td>\n",
       "      <td>Anna Lee C. Iijima</td>\n",
       "      <td>Guillaume Gonnet 2016 La Muse Red (Châteauneuf...</td>\n",
       "      <td>Rhône-style Red Blend</td>\n",
       "      <td>Guillaume Gonnet</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0    France  Buxom and heady, this is a delightfully rich, ...   \n",
       "1    France  Sultry and silken on the palate, this wine sta...   \n",
       "2  Portugal  The wine's fine perfumed black plum fruits giv...   \n",
       "3    France  Veins of vanilla, smoke and toast amplify blac...   \n",
       "4    France  This juicy, fruit-forward wine drenches the pa...   \n",
       "\n",
       "                designation  points  price             province      region_1  \\\n",
       "0           Vieilles Vignes      99  114.0  Châteauneuf-du-Pape  Rhône Valley   \n",
       "1                La Réserve      98  175.0  Châteauneuf-du-Pape  Rhône Valley   \n",
       "2                       NaN      98  120.0                 Port    Port Blend   \n",
       "3  Hommage à Henry Tacussel      98   80.0  Châteauneuf-du-Pape  Rhône Valley   \n",
       "4                   La Muse      97   88.0  Châteauneuf-du-Pape  Rhône Valley   \n",
       "\n",
       "          taster_name                                              title  \\\n",
       "0  Anna Lee C. Iijima  Domaine de la Janasse 2016 Vieilles Vignes Red...   \n",
       "1  Anna Lee C. Iijima  Domaine le Clos du Caillou 2016 La Réserve Red...   \n",
       "2          Roger Voss                                 Fonseca 2017  Port   \n",
       "3  Anna Lee C. Iijima  Domaine Moulin-Tacussel 2016 Hommage à Henry T...   \n",
       "4  Anna Lee C. Iijima  Guillaume Gonnet 2016 La Muse Red (Châteauneuf...   \n",
       "\n",
       "                 variety                      winery  vintage  \n",
       "0  Rhône-style Red Blend       Domaine de la Janasse   2016.0  \n",
       "1  Rhône-style Red Blend  Domaine le Clos du Caillou   2016.0  \n",
       "2                   Port                     Fonseca   2017.0  \n",
       "3               Grenache     Domaine Moulin-Tacussel   2016.0  \n",
       "4  Rhône-style Red Blend            Guillaume Gonnet   2016.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, subset=['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 countries producing wine in this dataset such as France, Portugal, Italy, US, Chile... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} countries producing wine in this dataset such as {}... \\n\".\n",
    "      format(len(df.country.unique()), \", \".join(df.country.unique()[0:5])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country baseline is 0.3593197943297044\n"
     ]
    }
   ],
   "source": [
    "print('The country baseline is', df.country.value_counts(normalize=True).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34813x15200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 910512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(strip_accents='unicode',\n",
    "                       stop_words=\"english\", \n",
    "                       ngram_range=(1, 1))\n",
    "\n",
    "X_all = cvec.fit_transform(df['description'])\n",
    "columns = cvec.get_feature_names()\n",
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE THE VARIABLE COUNTRY AS A TARGET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.description\n",
    "y = df.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT VECTORIZER  AND LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Count Vectorizer:\n",
    "- I am using stip_accents to Remove accents and perform other character normalization.\n",
    "- I used 'stop_words' inside the CountVectorizer because I am going to eliminate most of the common words like 'and', 'the', 'of',..... that they are not relevant for the determining wine language.\n",
    "- the ngram_range is (1,1) because I only want to extract 1 word.\n",
    "\n",
    "In Logistic Regression:\n",
    "- 'l1' I am using Lasso and 'l2' Ridge regulation. \n",
    "- 'saga' this parameter handle with Lasso regulation and it's faster than 'liblinear'.\n",
    "- 'lbfgs' with Ridge regulation\n",
    "- 'ovr' in multiclass in the first performance. I change it to 'Multinomial' in the second performance but the accurancy was higher in the first. \n",
    "- 'random_state' I am going to use the default because I am using 'saga' as a solver.\n",
    "\n",
    "The best performed model was when I used Ridge regularization and with mult_class ovr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9133993968117191"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer and Logistic Regression with Ridge Regularization and multiclass 'ovr' \n",
    "pipeline_ridge = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l2', solver='lbfgs', multi_class='ovr', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipeline_ridge.fit(X_train, y_train)\n",
    "predicted_ridge = pipeline_ridge.predict(X_test)\n",
    "pipeline_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Argentina       0.70      0.48      0.57       127\n",
      "   Australia       0.79      0.89      0.83       173\n",
      "     Austria       0.88      0.82      0.85       182\n",
      "      Brazil       0.00      0.00      0.00         2\n",
      "    Bulgaria       0.53      0.80      0.64        10\n",
      "      Canada       0.00      0.00      0.00        12\n",
      "       Chile       0.55      0.44      0.49       142\n",
      "     Croatia       0.00      0.00      0.00         3\n",
      "     England       1.00      0.22      0.36         9\n",
      "      France       0.88      0.96      0.92      1461\n",
      "     Georgia       0.80      0.44      0.57         9\n",
      "     Germany       0.95      0.92      0.93       120\n",
      "      Greece       1.00      1.00      1.00        21\n",
      "     Hungary       0.80      0.67      0.73         6\n",
      "       India       0.00      0.00      0.00         1\n",
      "      Israel       0.80      0.97      0.88        36\n",
      "       Italy       0.98      0.98      0.98       927\n",
      "      Kosovo       0.00      0.00      0.00         3\n",
      "     Lebanon       0.00      0.00      0.00         1\n",
      "  Luxembourg       0.00      0.00      0.00         1\n",
      "     Moldova       0.50      0.36      0.42        14\n",
      "     Morocco       0.00      0.00      0.00         1\n",
      " New Zealand       0.81      0.65      0.72       121\n",
      "      Oregon       0.96      0.97      0.97       366\n",
      "        Peru       0.00      0.00      0.00         1\n",
      "    Portugal       0.91      0.67      0.77       360\n",
      "     Romania       0.60      0.75      0.67        12\n",
      "      Serbia       0.00      0.00      0.00         2\n",
      "    Slovenia       0.00      0.00      0.00         2\n",
      "South Africa       0.74      0.59      0.66        34\n",
      "       Spain       0.70      0.89      0.78       312\n",
      " Switzerland       0.33      0.50      0.40         4\n",
      "      Turkey       0.00      0.00      0.00         1\n",
      "          US       0.99      0.99      0.99      2470\n",
      "     Uruguay       1.00      0.24      0.38        17\n",
      "\n",
      "    accuracy                           0.91      6963\n",
      "   macro avg       0.52      0.46      0.47      6963\n",
      "weighted avg       0.91      0.91      0.91      6963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 out of  37 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    3.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    3.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    3.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91013247 0.91178053 0.9091725  0.90577234 0.91143114]\n",
      "0.9096577975748428\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipeline_ridge, X_train, y_train, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 8 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 9 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 19 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 10 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 10 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9112451529513141"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer and Logistic Regression with Lasso Regularization and multiclass 'ovr' \n",
    "pipelinea = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='ovr', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipelinea.fit(X_train, y_train)\n",
    "predicteda = pipelinea.predict(X_test)\n",
    "pipelinea.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Argentina       0.72      0.50      0.59       127\n",
      "   Australia       0.79      0.87      0.82       173\n",
      "     Austria       0.86      0.84      0.85       182\n",
      "      Brazil       0.00      0.00      0.00         2\n",
      "    Bulgaria       0.56      0.90      0.69        10\n",
      "      Canada       0.00      0.00      0.00        12\n",
      "       Chile       0.59      0.45      0.51       142\n",
      "     Croatia       0.00      0.00      0.00         3\n",
      "     England       0.50      0.33      0.40         9\n",
      "      France       0.88      0.95      0.92      1461\n",
      "     Georgia       0.57      0.44      0.50         9\n",
      "     Germany       0.93      0.89      0.91       120\n",
      "      Greece       1.00      1.00      1.00        21\n",
      "     Hungary       1.00      0.33      0.50         6\n",
      "       India       0.00      0.00      0.00         1\n",
      "      Israel       0.81      0.94      0.87        36\n",
      "       Italy       0.98      0.98      0.98       927\n",
      "      Kosovo       0.00      0.00      0.00         3\n",
      "     Lebanon       0.00      0.00      0.00         1\n",
      "  Luxembourg       0.00      0.00      0.00         1\n",
      "     Moldova       0.50      0.29      0.36        14\n",
      "     Morocco       0.00      0.00      0.00         1\n",
      " New Zealand       0.78      0.66      0.71       121\n",
      "      Oregon       0.96      0.96      0.96       366\n",
      "        Peru       0.00      0.00      0.00         1\n",
      "    Portugal       0.91      0.65      0.76       360\n",
      "     Romania       0.64      0.75      0.69        12\n",
      "      Serbia       0.00      0.00      0.00         2\n",
      "    Slovenia       0.00      0.00      0.00         2\n",
      "South Africa       0.63      0.56      0.59        34\n",
      "       Spain       0.70      0.90      0.79       312\n",
      " Switzerland       0.22      0.50      0.31         4\n",
      "      Turkey       0.00      0.00      0.00         1\n",
      "          US       0.99      0.99      0.99      2470\n",
      "     Uruguay       1.00      0.24      0.38        17\n",
      "\n",
      "    accuracy                           0.91      6963\n",
      "   macro avg       0.50      0.46      0.46      6963\n",
      "weighted avg       0.91      0.91      0.91      6963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicteda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 out of  37 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91013247 0.90998745 0.909711   0.90972847 0.91269127]\n",
      "0.9104501322263772\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipelinea, X_train, y_train, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9123940830101968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer and Logistic Regression with Lasso Regularization and multiclass 'multinomial' \n",
    "pipeline = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='multinomial', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDFVECTORIZER  AND LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer just counts the word frequencies. The TFIDFVectorizer count the word frequencies and compute the Inverse Document Frequency values, that measure how much information the word provide (whether the term is common or rare in all the documents).\n",
    "\n",
    "I am going to define the same parameters that I used with CountVectorize but I am going to include sublinear_tf to scale tf and max_features = 2000 that only is going to consider the top 2000 max_features ordered by term frequency across the corpus.\n",
    "\n",
    "In Logistic Regression and GridsearchCV the parameters are going to be the same than I defined above.\n",
    "\n",
    "The best model performer was when I included the Lasso regularization with all the features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9003303173919288"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TdidfVectorizer and Logistic Regression with Ridge regularizarion\n",
    "pipeline_ridge = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', LogisticRegression(penalty = 'l2', solver='lbfgs', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipeline_ridge.fit(X_train, y_train)\n",
    "predicted_ridge = pipeline_ridge.predict(X_test)\n",
    "pipeline_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9065058164584231"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TdidfVectorizer and Logistic Regression with Ridge regularizarion and multiclas 'ovr'\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='ovr'))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9063622002010627"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TdidfVectorizer and Logistic Regression with Ridge regularizarion and multiclass 'multinomial'\n",
    "pipelinesv = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial'))\n",
    "])\n",
    "pipelinesv.fit(X_train, y_train)\n",
    "predictedsv = pipelinesv.predict(X_test)\n",
    "pipelinesv.score(X_test, y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9096653741203504"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDFVECTORIZER AND LOGISTIC REGRESSION inluding Lasso regularization and mulinomial as a multiclass\n",
    "pipelinesv = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial', penalty = 'l1'))\n",
    "])\n",
    "pipelinesv.fit(X_train, y_train)\n",
    "predictedsv = pipelinesv.predict(X_test)\n",
    "pipelinesv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9053568863995404"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDFVECTORIZER AND LOGISTIC REGRESSION inluding Lasso regularization and max_features = 2000\n",
    "pipelinesv = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode',  max_features = 2000)),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial', penalty = 'l1'))\n",
    "])\n",
    "pipelinesv.fit(X_train, y_train)\n",
    "predictedsv = pipelinesv.predict(X_test)\n",
    "pipelinesv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053568863995404"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDFVECTORIZER AND LOGISTIC REGRESSION inluding Ridge regularization solver sag.\n",
    "pipelinesv = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', LogisticRegression(solver='sag', multi_class='multinomial', penalty = 'l2'))\n",
    "])\n",
    "pipelinesv.fit(X_train, y_train)\n",
    "predictedsv = pipelinesv.predict(X_test)\n",
    "pipelinesv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER, COUNTVECTORIZER AND TFDFVECTORIZER\n",
    "\n",
    "I am going to use Random Forests Classifier because is one of the most widespread classifiers and it has the power to handle a large data set with higher dimensionality. Random forests is considered as a highly accurate and robust method because of the number of decision trees participating in the process.\n",
    "It does not suffer from the overfitting problem. The main reason is that it takes the average of all the predictions, which cancels out the biases. \n",
    "\n",
    "The Random Forest Classifier parametres:\n",
    "\n",
    "- n_estimators represents the number of trees in the forest. Usually the higher the number of trees the better to learn the data. However, adding a lot of trees can slow down the training process considerably, therefore I find the sweet spot in 200\n",
    "- n_jobs, we are defining 2 the number of jobs to run in parallel for both fit and predict\n",
    "- Max_dept represents the depth of each tree in the forest. The deeper the tree, the more splits it has and it captures more information about the data. I defined 10 in the last random forest and its the worst performer in all the models that I have created.   \n",
    "\n",
    "The difference between performs our model with TfidVectorizer or CountVectoriazer, does not differ some much. TfidVectorizer performs a littel bit better than CountVectoriazer.\n",
    "\n",
    "Logistic Regression perfoms better than Random Forest Classifier in this data set, with higher accuracy. Both of them have better scores than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8820910527071665"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with CountVectorizer\n",
    "cvecsr = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1),  max_features=1000)\n",
    "pipelinesr = Pipeline([\n",
    "    ('vect', cvecsr),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2))\n",
    "])\n",
    "pipelinesr.fit(X_train, y_train)\n",
    "predictedsr = pipelinesr.predict(X_test)\n",
    "pipelinesr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822346689645267"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with TfidfVectorizer\n",
    "pipelinesr = Pipeline([\n",
    "    ('vect', vect),\n",
    "    \n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2))\n",
    "])\n",
    "pipelinesr.fit(X_train, y_train)\n",
    "predictedsr = pipelinesr.predict(X_test)\n",
    "pipelinesr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6882091052707167"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with TfidfVectorizer and max_depth = 10\n",
    "pipelinesr = Pipeline([\n",
    "    ('vect', vect),\n",
    "    \n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2, max_depth = 10 ))\n",
    "])\n",
    "pipelinesr.fit(X_train, y_train)\n",
    "predictedsr = pipelinesr.predict(X_test)\n",
    "pipelinesr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES, COUNTVECTORIZER AND TFDFVECTORIZER\n",
    "\n",
    "Naive Bayes is a classification algorithm relying on Bayes' rule. As in all other classification models, one is interested in determining the probability of having a certain class label when a certain combination of feature values is obtained\n",
    "\n",
    "I am going to use MultinomialNB and BernoullinNB. Both of them are suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.\n",
    "\n",
    "The best accuracy I got in MultinomialNB with CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(lowercase=True, strip_accents='unicode', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7834266839006175"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with CountVectorizer and TfidTransformer\n",
    "pipelinesn = Pipeline([\n",
    "    ('vect', cvect),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinesn.fit(X_train, y_train)\n",
    "predictedsn = pipelinesn.predict(X_test)\n",
    "pipelinesn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710326008904208"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with CountVectorizer\n",
    "pipelinesn1 = Pipeline([\n",
    "    ('vect', cvect),\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinesn1.fit(X_train, y_train)\n",
    "predictedsn1 = pipelinesn1.predict(X_test)\n",
    "pipelinesn1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8593996840442338"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BernoulliNB with CountVectorizer\n",
    "pipelinesn2 = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', BernoulliNB())\n",
    "])\n",
    "pipelinesn2.fit(X_train, y_train)\n",
    "predictedsn2 = pipelinesn2.predict(X_test)\n",
    "pipelinesn2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1 = TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837139164153382"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with TfidfVectorizer \n",
    "pipelinesn3 = Pipeline([\n",
    "    ('vect',vect1) ,\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinesn3.fit(X_train, y_train)\n",
    "predictedsn3 = pipelinesn3.predict(X_test)\n",
    "pipelinesn3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8593996840442338"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BernoulliNB with TfidfVectorizer\n",
    "pipelinesn4 = Pipeline([\n",
    "    ('vect', vect1),\n",
    "    ('cls', BernoulliNB())\n",
    "])\n",
    "pipelinesn4.fit(X_train, y_train)\n",
    "predictedsn4 = pipelinesn4.predict(X_test)\n",
    "pipelinesn4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuray is in Logistic Regression model with Lasso regularization. With Random Forest I got higher accuracy than with Naives Bayes but the difference is not huge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMALL DATA WITH COUNTRIES REDUCTIONS AND DATA STRATIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to work with the countries more representatives, that appear more than 10 times because will not be able to train and test on one sample.\n",
    "\n",
    "\n",
    "I am only going to perform the models that worked better before. \n",
    "\n",
    "As happened before, the best accuracy was in CountVectorizer and Logistic Regression with Ridge regularization. In this case the model training above without countries reductions and without data stratify works a little better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['country'].map(df['country'].value_counts()) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country reduction baseline is 0.360002302357038\n"
     ]
    }
   ],
   "source": [
    "print('The country reduction baseline is', df1.country.value_counts(normalize=True).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df1.country\n",
    "X1 =  df1.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and stratify the data\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, stratify = y1, random_state= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logistic Regression, CountVectorizer and TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 9 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 10 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 18 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 11 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 9 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  26 out of  26 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9138129496402878"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNTVECTORIZER AND LOGISTIC REGRESSION inluding Ridge regularization\n",
    "cvec1 = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1))\n",
    "pipeline1 = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='ovr', n_jobs=2, verbose = 1)\n",
    "    )])\n",
    "pipeline1.fit(X_train1, y_train1)\n",
    "predicted1 = pipeline1.predict(X_test1)\n",
    "pipeline1.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Argentina       0.66      0.45      0.53       130\n",
      "   Australia       0.83      0.86      0.84       162\n",
      "     Austria       0.85      0.87      0.86       183\n",
      "      Brazil       0.00      0.00      0.00         2\n",
      "    Bulgaria       0.64      1.00      0.78         7\n",
      "      Canada       0.00      0.00      0.00        10\n",
      "       Chile       0.63      0.54      0.58       158\n",
      "     Croatia       0.00      0.00      0.00         3\n",
      "     England       0.75      0.55      0.63        11\n",
      "      France       0.88      0.96      0.92      1488\n",
      "     Georgia       0.75      0.33      0.46         9\n",
      "     Germany       0.94      0.83      0.88       123\n",
      "      Greece       1.00      1.00      1.00        18\n",
      "     Hungary       0.67      0.80      0.73         5\n",
      "      Israel       0.84      0.97      0.90        32\n",
      "       Italy       0.98      0.98      0.98       912\n",
      "     Moldova       0.50      0.29      0.36         7\n",
      " New Zealand       0.77      0.73      0.75       107\n",
      "      Oregon       0.97      0.96      0.96       352\n",
      "    Portugal       0.89      0.61      0.73       334\n",
      "     Romania       0.85      1.00      0.92        11\n",
      "South Africa       0.84      0.47      0.60        34\n",
      "       Spain       0.71      0.87      0.78       331\n",
      " Switzerland       0.33      0.25      0.29         4\n",
      "          US       0.99      0.99      0.99      2502\n",
      "     Uruguay       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.91      6950\n",
      "   macro avg       0.70      0.64      0.66      6950\n",
      "weighted avg       0.91      0.91      0.91      6950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  26 out of  26 | elapsed:   55.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  26 out of  26 | elapsed:   51.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  26 out of  26 | elapsed:   53.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  26 out of  26 | elapsed:   52.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  26 out of  26 | elapsed:   52.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91132651 0.92006467 0.912527   0.91015484 0.91007389]\n",
      "0.912829381493086\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipeline1, X_train1, y_train1, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9133993968117191"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNTVECTORIZER AND LOGISTIC REGRESSION inluding Lasso regularization\n",
    "pipeline_ridge = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l2', solver='lbfgs', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipeline_ridge.fit(X_train, y_train)\n",
    "predicted_ridge = pipeline_ridge.predict(X_test)\n",
    "pipeline_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 out of  37 | elapsed:    4.6s finished\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    3.8s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.0s finished\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    3.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.1s finished\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    3.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.1s finished\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  39 | elapsed:    4.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  39 out of  39 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91013247 0.91178053 0.9091725  0.90577234 0.91143114]\n",
      "0.9096577975748428\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipeline_ridge, X_train, y_train, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:   21.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9107913669064748"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDFVECTORIZER AND LOGISTIC REGRESSION inluding Lasso regularization\n",
    "pipelines1 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial', penalty = 'l1', n_jobs=2, verbose = 1))\n",
    "])\n",
    "pipelines1.fit(X_train1, y_train1)\n",
    "predicteds1 = pipelines1.predict(X_test1)\n",
    "pipelines1.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectrizer and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:   30.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8847535565454807"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TFIDFVECTORIZER AND RANDOM FORESTCLASSIFIER inluding Lasso regularization\n",
    "pipelinesr6 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    \n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2, verbose = 1))\n",
    "])\n",
    "pipelinesr6.fit(X_train1, y_train1)\n",
    "predictedsr6 = pipelinesr6.predict(X_test1)\n",
    "pipelinesr6.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naives Bayes, CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716769650811899"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with CountVectorizer\n",
    "cvect1 = CountVectorizer(lowercase=True, strip_accents='unicode', stop_words='english')\n",
    "pipelinesn2 = Pipeline([\n",
    "    ('vect', cvect1),\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinesn2.fit(X_train1, y_train1)\n",
    "predictedsn2 = pipelinesn2.predict(X_test1)\n",
    "pipelinesn2.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577381807730996"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')\n",
    "# BernoulliNB with  TfidfVectorizer\n",
    "pipelinesn5 = Pipeline([\n",
    "    ('vect', vect1),\n",
    "    ('cls', BernoulliNB())\n",
    "])\n",
    "pipelinesn5.fit(X_train1, y_train1)\n",
    "predictedsn5 = pipelinesn5.predict(X_test1)\n",
    "pipelinesn5.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As happened in the small data set the best accuray is in Logistic Regression model with Lasso regularization. With Random Forest I got higher accuracy than with Naives Bayes but the difference is not huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vino = pd.read_csv('big_wineV1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "      <td>Ars In Vitro</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Navarra</td>\n",
       "      <td>Michael Schachner</td>\n",
       "      <td>Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...</td>\n",
       "      <td>Tempranillo-Merlot</td>\n",
       "      <td>Tandem</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "1           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "2           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "3           4        US  Much like the regular bottling from 2012, this...   \n",
       "4           5     Spain  Blackberry and raspberry aromas show a typical...   \n",
       "\n",
       "                          designation  points  price        province  \\\n",
       "0                            Avidagos      87   15.0           Douro   \n",
       "1                                 NaN      87   14.0          Oregon   \n",
       "2                Reserve Late Harvest      87   13.0        Michigan   \n",
       "3  Vintner's Reserve Wild Child Block      87   65.0          Oregon   \n",
       "4                        Ars In Vitro      87   15.0  Northern Spain   \n",
       "\n",
       "              region_1         taster_name  \\\n",
       "0                  NaN          Roger Voss   \n",
       "1    Willamette Valley        Paul Gregutt   \n",
       "2  Lake Michigan Shore  Alexander Peartree   \n",
       "3    Willamette Valley        Paul Gregutt   \n",
       "4              Navarra   Michael Schachner   \n",
       "\n",
       "                                               title             variety  \\\n",
       "0      Quinta dos Avidagos 2011 Avidagos Red (Douro)      Portuguese Red   \n",
       "1      Rainstorm 2013 Pinot Gris (Willamette Valley)          Pinot Gris   \n",
       "2  St. Julian 2013 Reserve Late Harvest Riesling ...            Riesling   \n",
       "3  Sweet Cheeks 2012 Vintner's Reserve Wild Child...          Pinot Noir   \n",
       "4  Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...  Tempranillo-Merlot   \n",
       "\n",
       "                winery  vintage  \n",
       "0  Quinta dos Avidagos   2011.0  \n",
       "1            Rainstorm   2013.0  \n",
       "2           St. Julian   2013.0  \n",
       "3         Sweet Cheeks   2012.0  \n",
       "4               Tandem   2011.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 743 types of grapes(varieties) in this dataset such as Portuguese Red, Pinot Gris, Riesling, Pinot Noir, Tempranillo-Merlot... \n",
      "\n",
      "There are 450 provinces producing wine in this dataset such as Douro, Oregon, Michigan, Northern Spain, Sicily & Sardinia... \n",
      "\n",
      "There are 43 countries producing wine in this dataset such as Portugal, US, Spain, Italy, France... \n",
      "\n",
      "There are 17390 winery producing wine in this dataset such as Quinta dos Avidagos, Rainstorm, St. Julian, Sweet Cheeks, Tandem... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} types of grapes(varieties) in this dataset such as {}... \\n\".\n",
    "      format(len(vino.variety.unique()), \", \".join(vino.variety.unique()[0:5])))\n",
    "print(\"There are {} provinces producing wine in this dataset such as {}... \\n\".\n",
    "      format(len(vino.province.unique()), \", \".join(vino.province.unique()[0:5])))\n",
    "print(\"There are {} countries producing wine in this dataset such as {}... \\n\".\n",
    "      format(len(vino.country.unique()), \", \".join(vino.country.unique()[0:5]))) \n",
    "print(\"There are {} winery producing wine in this dataset such as {}... \\n\".\n",
    "      format(len(vino.winery.unique()), \", \".join(vino.winery.unique()[0:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baselines of my features are:\n",
      "The country baseline is 0.4436020682021501\n",
      "The variety baseline is 0.10773989583096413\n",
      "The province baseline is 0.2948097830207275\n"
     ]
    }
   ],
   "source": [
    "print('The baselines of my features are:')\n",
    "print('The country baseline is', vino.country.value_counts(normalize=True).max())\n",
    "print('The variety baseline is', vino.variety.value_counts(normalize=True).max())\n",
    "print('The province baseline is', vino.province.value_counts(normalize=True).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE THE VARIABLE COUNTRY AS A TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target is the variable 'country'. This datset has 43 differentes countries.\n",
    "yb = vino.country\n",
    "Xb =  vino.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_trainb, X_testb, y_trainb, y_testb = train_test_split(Xb, yb, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNTVECTORIZER  AND LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores did not differ so much but the best performed model was with CountVectorizer and Logistic Regression with Ridge Regularization and multiclass ovr. I calculated the cross validation in this model and the score does not differ so much than the accuracy score.\n",
    " \n",
    "All of the models have better scores than the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  43 out of  43 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8517872711421098"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer and Logistic Regression with Ridge regularization\n",
    "pipeline_ridge = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l2', solver='lbfgs', multi_class='ovr', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipeline_ridge.fit(X_trainb, y_trainb)\n",
    "predicted_ridge = pipeline_ridge.predict(X_testb)\n",
    "pipeline_ridge.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             Argentina       0.58      0.47      0.52       796\n",
      "             Australia       0.74      0.57      0.64       490\n",
      "               Austria       0.76      0.66      0.70       572\n",
      "Bosnia and Herzegovina       0.00      0.00      0.00         1\n",
      "                Brazil       0.00      0.00      0.00        11\n",
      "              Bulgaria       0.79      0.54      0.64        28\n",
      "                Canada       0.00      0.00      0.00        48\n",
      "                 Chile       0.61      0.54      0.57       964\n",
      "                 China       0.00      0.00      0.00         3\n",
      "               Croatia       0.60      0.21      0.32        14\n",
      "                Cyprus       0.00      0.00      0.00         2\n",
      "        Czech Republic       0.00      0.00      0.00         5\n",
      "               England       1.00      0.11      0.19        19\n",
      "                France       0.80      0.87      0.83      3940\n",
      "               Georgia       0.60      0.25      0.35        12\n",
      "               Germany       0.73      0.68      0.70       471\n",
      "                Greece       0.75      0.61      0.67        87\n",
      "               Hungary       0.87      0.45      0.59        29\n",
      "                 India       0.00      0.00      0.00         1\n",
      "                Israel       0.66      0.47      0.55       121\n",
      "                 Italy       0.96      0.96      0.96      3701\n",
      "                Kosovo       0.00      0.00      0.00         1\n",
      "               Lebanon       0.00      0.00      0.00        10\n",
      "            Luxembourg       0.00      0.00      0.00         3\n",
      "             Macedonia       0.00      0.00      0.00         3\n",
      "                Mexico       0.00      0.00      0.00        16\n",
      "               Moldova       0.58      0.35      0.44        20\n",
      "               Morocco       0.00      0.00      0.00         4\n",
      "           New Zealand       0.71      0.54      0.61       280\n",
      "                  Peru       0.00      0.00      0.00         4\n",
      "              Portugal       0.88      0.55      0.68      1093\n",
      "               Romania       0.80      0.17      0.28        24\n",
      "                Serbia       0.00      0.00      0.00         3\n",
      "              Slovenia       0.50      0.03      0.06        30\n",
      "          South Africa       0.64      0.62      0.63       242\n",
      "                 Spain       0.71      0.74      0.73      1451\n",
      "           Switzerland       1.00      0.50      0.67         2\n",
      "                Turkey       0.00      0.00      0.00        14\n",
      "                    US       0.91      0.97      0.94     11837\n",
      "               Ukraine       0.00      0.00      0.00         5\n",
      "               Uruguay       1.00      0.42      0.59        24\n",
      "\n",
      "              accuracy                           0.85     26381\n",
      "             macro avg       0.44      0.30      0.34     26381\n",
      "          weighted avg       0.84      0.85      0.84     26381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_testb, predicted_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  41 out of  41 | elapsed:   21.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  43 out of  43 | elapsed:   22.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  43 out of  43 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  43 out of  43 | elapsed:   20.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  43 out of  43 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85395067 0.85283251 0.85332449 0.85063519 0.85509033]\n",
      "0.8531666384300459\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipeline_ridge, X_trainb, y_trainb, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.849740343428983"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer and Logistic Regression with Lasso regularization\n",
    "cvec = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1))\n",
    "pipeline = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='ovr'))\n",
    "])\n",
    "pipeline.fit(X_trainb, y_trainb)\n",
    "predicted = pipeline.predict(X_testb)\n",
    "pipeline.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             Argentina       0.61      0.45      0.52       796\n",
      "             Australia       0.74      0.55      0.63       490\n",
      "               Austria       0.75      0.67      0.71       572\n",
      "Bosnia and Herzegovina       0.00      0.00      0.00         1\n",
      "                Brazil       0.00      0.00      0.00        11\n",
      "              Bulgaria       0.68      0.46      0.55        28\n",
      "                Canada       0.00      0.00      0.00        48\n",
      "                 Chile       0.61      0.55      0.58       964\n",
      "                 China       0.00      0.00      0.00         3\n",
      "               Croatia       0.71      0.36      0.48        14\n",
      "                Cyprus       0.00      0.00      0.00         2\n",
      "        Czech Republic       0.00      0.00      0.00         5\n",
      "               England       0.33      0.05      0.09        19\n",
      "                France       0.79      0.87      0.83      3940\n",
      "               Georgia       0.75      0.25      0.38        12\n",
      "               Germany       0.73      0.68      0.71       471\n",
      "                Greece       0.68      0.61      0.64        87\n",
      "               Hungary       0.87      0.45      0.59        29\n",
      "                 India       0.00      0.00      0.00         1\n",
      "                Israel       0.62      0.40      0.49       121\n",
      "                 Italy       0.96      0.96      0.96      3701\n",
      "                Kosovo       0.00      0.00      0.00         1\n",
      "               Lebanon       0.00      0.00      0.00        10\n",
      "            Luxembourg       0.00      0.00      0.00         3\n",
      "             Macedonia       0.00      0.00      0.00         3\n",
      "                Mexico       0.00      0.00      0.00        16\n",
      "               Moldova       0.70      0.35      0.47        20\n",
      "               Morocco       0.00      0.00      0.00         4\n",
      "           New Zealand       0.70      0.51      0.59       280\n",
      "                  Peru       0.00      0.00      0.00         4\n",
      "              Portugal       0.89      0.54      0.68      1093\n",
      "               Romania       0.67      0.17      0.27        24\n",
      "                Serbia       0.00      0.00      0.00         3\n",
      "              Slovenia       1.00      0.07      0.12        30\n",
      "          South Africa       0.65      0.60      0.63       242\n",
      "                 Spain       0.70      0.75      0.73      1451\n",
      "           Switzerland       0.00      0.00      0.00         2\n",
      "                Turkey       0.00      0.00      0.00        14\n",
      "                    US       0.90      0.97      0.93     11837\n",
      "               Ukraine       0.00      0.00      0.00         5\n",
      "               Uruguay       1.00      0.42      0.59        24\n",
      "\n",
      "              accuracy                           0.85     26381\n",
      "             macro avg       0.42      0.29      0.32     26381\n",
      "          weighted avg       0.84      0.85      0.84     26381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_testb, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85238839 0.85098522 0.85128667 0.85006636 0.85362037]\n",
      "0.8516694032909164\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipeline, X_trainb, y_trainb, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1346 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed: 22.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8528865471361965"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer and Logistic Regression with Lasso regularizarion and multinomial multiclass\n",
    "cvecb = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1))\n",
    "pipelineb = Pipeline([ \n",
    "    ('vect', cvecb),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='multinomial',verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipelineb.fit(X_trainb, y_trainb)\n",
    "predictedb = pipelineb.predict(X_testb)\n",
    "pipelineb.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             Argentina       0.58      0.50      0.54       795\n",
      "               Armenia       0.00      0.00      0.00         1\n",
      "             Australia       0.71      0.59      0.64       513\n",
      "               Austria       0.75      0.67      0.71       616\n",
      "Bosnia and Herzegovina       0.00      0.00      0.00         1\n",
      "                Brazil       1.00      0.07      0.13        14\n",
      "              Bulgaria       0.74      0.57      0.64        30\n",
      "                Canada       0.57      0.08      0.14        51\n",
      "                 Chile       0.61      0.55      0.58       920\n",
      "               Croatia       0.60      0.18      0.27        17\n",
      "                Cyprus       0.00      0.00      0.00         4\n",
      "               England       0.60      0.43      0.50        14\n",
      "                France       0.81      0.85      0.83      4125\n",
      "               Georgia       0.38      0.21      0.27        14\n",
      "               Germany       0.79      0.69      0.74       492\n",
      "                Greece       0.85      0.71      0.77        93\n",
      "               Hungary       0.76      0.38      0.51        42\n",
      "                 India       0.00      0.00      0.00         4\n",
      "                Israel       0.61      0.47      0.53       114\n",
      "                 Italy       0.97      0.95      0.96      3741\n",
      "                Kosovo       0.00      0.00      0.00         4\n",
      "               Lebanon       0.00      0.00      0.00         5\n",
      "            Luxembourg       0.00      0.00      0.00         2\n",
      "             Macedonia       0.00      0.00      0.00         2\n",
      "                Mexico       0.50      0.06      0.10        18\n",
      "               Moldova       0.71      0.28      0.40        18\n",
      "               Morocco       0.00      0.00      0.00         5\n",
      "           New Zealand       0.68      0.56      0.61       299\n",
      "                  Peru       0.00      0.00      0.00         3\n",
      "              Portugal       0.82      0.62      0.71      1078\n",
      "               Romania       0.62      0.53      0.57        15\n",
      "                Serbia       0.00      0.00      0.00         1\n",
      "              Slovenia       0.17      0.08      0.11        12\n",
      "          South Africa       0.68      0.59      0.63       266\n",
      "                 Spain       0.71      0.76      0.74      1426\n",
      "           Switzerland       0.00      0.00      0.00         2\n",
      "                Turkey       0.30      0.25      0.27        12\n",
      "                    US       0.91      0.96      0.94     11593\n",
      "               Ukraine       0.00      0.00      0.00         1\n",
      "               Uruguay       1.00      0.50      0.67        18\n",
      "\n",
      "              accuracy                           0.85     26381\n",
      "             macro avg       0.46      0.33      0.36     26381\n",
      "          weighted avg       0.85      0.85      0.85     26381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_testb, predictedb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDFVECTORIZER  AND LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defineded the same model thay worked better in the small dataset. I compared including max_features in the first and including Lasso regularization in the second.\n",
    "The best accuracy is with the Lasso regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8124028656987984"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TfidVectorizer and Logisitic Regression with max_features = 1000\n",
    "pipelinev = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True, max_features=1000,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial'))\n",
    "])\n",
    "pipelinev.fit(X_trainb, y_trainb)\n",
    "predictedv = pipelinev.predict(X_testb)\n",
    "pipelinev.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8509533376293544"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidVectorizer and Logisitic Regression without max_features = 1000 and include Lasso regularization\n",
    "pipelinev = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial', penalty = 'l1' ))\n",
    "])\n",
    "pipelinev.fit(X_trainb, y_trainb)\n",
    "predictedv = pipelinev.predict(X_testb)\n",
    "pipelinev.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER WITH COUNTVECTORIZER AND TFIDVECTORIZER \n",
    "\n",
    "Logistic Regression performs better than Random Forest Classifier in this data set, with higher accuracy.\n",
    "\n",
    "The best performed model was Random Forest with TfidVectorizer.\n",
    "\n",
    "All of the models have better scores than the baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478109245290171"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with CountVectorizer\n",
    "cvecbr = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1),  max_features=1000)\n",
    "pipelinebr = Pipeline([\n",
    "    ('vect', cvecbr),\n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2))\n",
    "])\n",
    "pipelinebr.fit(X_trainb, y_trainb)\n",
    "predictedbr = pipelinebr.predict(X_testb)\n",
    "pipelinebr.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511087525112771"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with CountVectorizer\n",
    "cvecbr = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1))\n",
    "pipelinebr = Pipeline([\n",
    "    ('vect', cvecbr),\n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2))\n",
    "])\n",
    "pipelinebr.fit(X_trainb, y_trainb)\n",
    "predictedbr = pipelinebr.predict(X_testb)\n",
    "pipelinebr.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511466585800387"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with TdfidVectorizer\n",
    "pipelinebr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    \n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2))\n",
    "])\n",
    "pipelinebr.fit(X_trainb, y_trainb)\n",
    "predictedbr = pipelinebr.predict(X_testb)\n",
    "pipelinebr.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NATIVE BAYES, COUNTVECTORIZER AND TFDFVECTORIZER\n",
    "\n",
    "As it happend in the small set the best acurracy I got in MultinomialNB with CountVectorizer. MultinomialNB is one of the two classic Naive Bayes variants used in text classification.\n",
    "\n",
    "Logistic Regression models perform better than Native Bayes in this data set, with higher accuracy.\n",
    "\n",
    "All of the models have better scores than the baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 1), strip_accents='unicode', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296160115234449"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with CountVectorizer\n",
    "pipelinebn = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinebn.fit(X_trainb, y_trainb)\n",
    "predictedbn = pipelinebn.predict(X_testb)\n",
    "pipelinebn.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195292066259808"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with CountVectorizer\n",
    "pipelinebn1 = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinebn1.fit(X_trainb, y_trainb)\n",
    "predictedbn1 = pipelinebn1.predict(X_testb)\n",
    "pipelinebn1.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81735549 0.81896552 0.81977157 0.81816458 0.81834132]\n",
      "0.8185196955332505\n"
     ]
    }
   ],
   "source": [
    "cross = cross_val_score(pipelinebn1, X_trainb, y_trainb, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8143739812744021"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "pipelinebn2 = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('cls', BernoulliNB())\n",
    "])\n",
    "pipelinebn2.fit(X_trainb, y_trainb)\n",
    "predictedbn2 = pipelinebn2.predict(X_testb)\n",
    "pipelinebn2.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1 = TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299571661422993"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with  TdidfVectorizer\n",
    "pipelinebn3 = Pipeline([\n",
    "    ('vect',vect1) ,\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinebn3.fit(X_trainb, y_trainb)\n",
    "predictedbn3 = pipelinebn3.predict(X_testb)\n",
    "pipelinebn3.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8143739812744021"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "pipelinebn4 = Pipeline([\n",
    "    ('vect', vect1),\n",
    "    ('cls', BernoulliNB())\n",
    "])\n",
    "pipelinebn4.fit(X_trainb, y_trainb)\n",
    "predictedbn4 = pipelinebn4.predict(X_testb)\n",
    "pipelinebn4.score(X_testb, y_testb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performer model was CountVectorizer with Logistic Regression and Ridge regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG DATA WITH COUNTRY REDUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contain the wines that appear more than 10 times.\n",
    "\n",
    "I am going to train and test the models that preformed better above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the data, target, predictor and split and stratify it.\n",
    "vino1 = vino[vino['country'].map(vino['country'].value_counts()) > 10]\n",
    "y1 = vino1.country\n",
    "X1 =  vino1.description\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, stratify = y1, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variety baseline is 0.10777643784083066\n"
     ]
    }
   ],
   "source": [
    "print('The variety baseline is', vino1.variety.value_counts(normalize=True).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vino1.country.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LOGISTIC REGRESSION, COUNTVECTORIZER AND TFIDFVECTORIZER  \n",
    "\n",
    "The scores did not differ so much but the best performed model was with CountVectorizer and Logistic Regression with Ridge Regularization and multiclass ovr. I calculated the cross validation in this model and the score does not differ so much than the accuracy score.\n",
    "\n",
    "All of the models have better scores than the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 112 seconds\n",
      "max_iter reached after 112 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 22 seconds\n",
      "max_iter reached after 27 seconds\n",
      "max_iter reached after 44 seconds\n",
      "max_iter reached after 99 seconds\n",
      "max_iter reached after 26 seconds\n",
      "max_iter reached after 17 seconds\n",
      "max_iter reached after 23 seconds\n",
      "max_iter reached after 119 seconds\n",
      "max_iter reached after 26 seconds\n",
      "max_iter reached after 79 seconds\n",
      "max_iter reached after 38 seconds\n",
      "max_iter reached after 213 seconds\n",
      "max_iter reached after 29 seconds\n",
      "max_iter reached after 50 seconds\n",
      "max_iter reached after 22 seconds\n",
      "max_iter reached after 16 seconds\n",
      "max_iter reached after 24 seconds\n",
      "max_iter reached after 127 seconds\n",
      "max_iter reached after 24 seconds\n",
      "max_iter reached after 20 seconds\n",
      "max_iter reached after 17 seconds\n",
      "max_iter reached after 84 seconds\n",
      "max_iter reached after 25 seconds\n",
      "max_iter reached after 97 seconds\n",
      "max_iter reached after 25 seconds\n",
      "max_iter reached after 70 seconds\n",
      "max_iter reached after 17 seconds\n",
      "max_iter reached after 26 seconds\n",
      "max_iter reached after 132 seconds\n",
      "max_iter reached after 16 seconds\n",
      "max_iter reached after 27 seconds\n",
      "max_iter reached after 289 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed: 19.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8528631020098597"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer and Logistic Regression with Lasso regularization\n",
    "cvec = CountVectorizer(strip_accents='unicode', stop_words=\"english\", ngram_range=(1, 1))\n",
    "pipelinesb1 = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l1', solver='saga', multi_class='ovr', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipelinesb1.fit(X_train1, y_train1)\n",
    "predictedsb1 = pipelinesb1.predict(X_test1)\n",
    "pipelinesb1.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Argentina       0.62      0.49      0.55       789\n",
      "     Australia       0.75      0.61      0.67       509\n",
      "       Austria       0.82      0.64      0.72       608\n",
      "        Brazil       0.00      0.00      0.00         9\n",
      "      Bulgaria       0.54      0.23      0.32        31\n",
      "        Canada       0.33      0.02      0.04        52\n",
      "         Chile       0.61      0.55      0.58       923\n",
      "       Croatia       0.86      0.38      0.52        16\n",
      "Czech Republic       0.00      0.00      0.00         3\n",
      "       England       0.33      0.12      0.18        16\n",
      "        France       0.80      0.88      0.84      4098\n",
      "       Georgia       0.00      0.00      0.00        16\n",
      "       Germany       0.78      0.67      0.72       484\n",
      "        Greece       0.71      0.59      0.64        93\n",
      "       Hungary       0.92      0.38      0.54        29\n",
      "        Israel       0.63      0.38      0.48       112\n",
      "         Italy       0.95      0.96      0.95      3688\n",
      "       Lebanon       0.00      0.00      0.00         6\n",
      "     Macedonia       0.00      0.00      0.00         2\n",
      "        Mexico       0.00      0.00      0.00        14\n",
      "       Moldova       0.75      0.19      0.30        16\n",
      "       Morocco       0.00      0.00      0.00         5\n",
      "   New Zealand       0.75      0.54      0.63       302\n",
      "          Peru       0.00      0.00      0.00         3\n",
      "      Portugal       0.88      0.56      0.68      1074\n",
      "       Romania       0.88      0.33      0.48        21\n",
      "      Slovenia       0.67      0.13      0.22        15\n",
      "  South Africa       0.64      0.58      0.61       268\n",
      "         Spain       0.72      0.75      0.74      1419\n",
      "   Switzerland       0.00      0.00      0.00         3\n",
      "        Turkey       0.40      0.11      0.17        18\n",
      "            US       0.90      0.97      0.93     11703\n",
      "       Ukraine       0.00      0.00      0.00         3\n",
      "       Uruguay       0.67      0.36      0.47        22\n",
      "\n",
      "      accuracy                           0.85     26370\n",
      "     macro avg       0.50      0.34      0.38     26370\n",
      "  weighted avg       0.84      0.85      0.84     26370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predictedsb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed: 13.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed: 13.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed: 13.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed: 13.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85380643 0.84861842 0.85116367 0.84776218 0.84929557]\n",
      "0.8501292565395634\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation Score\n",
    "cross = cross_val_score(pipelinesb1, X_train1, y_train1, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  34 out of  34 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8540766021994691"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer and Logistic Regression with Ridge regularization\n",
    "pipelinesb2 = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('cls', LogisticRegression(penalty = 'l2', solver='lbfgs', verbose = 1, n_jobs = 2))\n",
    "])\n",
    "pipelinesb2.fit(X_train1, y_train1)\n",
    "predictedsb2 = pipelinesb2.predict(X_test1)\n",
    "pipelinesb2.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84333697 0.83994502 0.84471726 0.83846956 0.84218016]\n",
      "0.841729793779019\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation Score\n",
    "cross = cross_val_score(pipelinesb2, X_train1, y_train1, cv=5)\n",
    "print(cross)\n",
    "print(cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Argentina       0.61      0.50      0.55       789\n",
      "     Australia       0.74      0.62      0.68       509\n",
      "       Austria       0.81      0.62      0.71       608\n",
      "        Brazil       0.00      0.00      0.00         9\n",
      "      Bulgaria       0.61      0.35      0.45        31\n",
      "        Canada       0.00      0.00      0.00        52\n",
      "         Chile       0.60      0.55      0.58       923\n",
      "       Croatia       0.71      0.31      0.43        16\n",
      "Czech Republic       0.00      0.00      0.00         3\n",
      "       England       0.67      0.25      0.36        16\n",
      "        France       0.80      0.88      0.84      4098\n",
      "       Georgia       0.00      0.00      0.00        16\n",
      "       Germany       0.79      0.68      0.73       484\n",
      "        Greece       0.75      0.58      0.65        93\n",
      "       Hungary       0.91      0.34      0.50        29\n",
      "        Israel       0.62      0.42      0.50       112\n",
      "         Italy       0.96      0.96      0.96      3688\n",
      "       Lebanon       0.00      0.00      0.00         6\n",
      "     Macedonia       0.00      0.00      0.00         2\n",
      "        Mexico       1.00      0.07      0.13        14\n",
      "       Moldova       0.80      0.25      0.38        16\n",
      "       Morocco       0.00      0.00      0.00         5\n",
      "   New Zealand       0.76      0.54      0.63       302\n",
      "          Peru       0.00      0.00      0.00         3\n",
      "      Portugal       0.86      0.57      0.69      1074\n",
      "       Romania       0.71      0.24      0.36        21\n",
      "      Slovenia       1.00      0.13      0.24        15\n",
      "  South Africa       0.66      0.60      0.63       268\n",
      "         Spain       0.72      0.74      0.73      1419\n",
      "   Switzerland       0.00      0.00      0.00         3\n",
      "        Turkey       0.50      0.11      0.18        18\n",
      "            US       0.90      0.97      0.93     11703\n",
      "       Ukraine       0.00      0.00      0.00         3\n",
      "       Uruguay       0.88      0.32      0.47        22\n",
      "\n",
      "      accuracy                           0.85     26370\n",
      "     macro avg       0.54      0.34      0.39     26370\n",
      "  weighted avg       0.85      0.85      0.85     26370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predictedsb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8496397421312097"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tdidf and Logistic Regression with Lasso regularization and Multinomial multiclass\n",
    "pipelinesb2 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    ('cls', LogisticRegression(solver='saga', multi_class='multinomial', penalty = 'l1' ))\n",
    "])\n",
    "pipelinesb2.fit(X_train1, y_train1)\n",
    "predictedsb2 = pipelinesb2.predict(X_test1)\n",
    "pipelinesb2.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mariagimenoperez/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Argentina       0.64      0.46      0.54       789\n",
      "     Australia       0.74      0.58      0.65       509\n",
      "       Austria       0.80      0.63      0.70       608\n",
      "        Brazil       0.00      0.00      0.00         9\n",
      "      Bulgaria       0.64      0.29      0.40        31\n",
      "        Canada       1.00      0.02      0.04        52\n",
      "         Chile       0.64      0.58      0.60       923\n",
      "       Croatia       1.00      0.38      0.55        16\n",
      "Czech Republic       0.00      0.00      0.00         3\n",
      "       England       0.50      0.12      0.20        16\n",
      "        France       0.80      0.87      0.83      4098\n",
      "       Georgia       0.00      0.00      0.00        16\n",
      "       Germany       0.79      0.62      0.69       484\n",
      "        Greece       0.74      0.55      0.63        93\n",
      "       Hungary       1.00      0.41      0.59        29\n",
      "        Israel       0.66      0.39      0.49       112\n",
      "         Italy       0.95      0.95      0.95      3688\n",
      "       Lebanon       0.00      0.00      0.00         6\n",
      "     Macedonia       0.00      0.00      0.00         2\n",
      "        Mexico       0.00      0.00      0.00        14\n",
      "       Moldova       1.00      0.12      0.22        16\n",
      "       Morocco       0.00      0.00      0.00         5\n",
      "   New Zealand       0.72      0.52      0.60       302\n",
      "          Peru       0.00      0.00      0.00         3\n",
      "      Portugal       0.86      0.57      0.68      1074\n",
      "       Romania       0.78      0.33      0.47        21\n",
      "      Slovenia       1.00      0.13      0.24        15\n",
      "  South Africa       0.67      0.56      0.61       268\n",
      "         Spain       0.71      0.77      0.74      1419\n",
      "   Switzerland       0.00      0.00      0.00         3\n",
      "        Turkey       0.00      0.00      0.00        18\n",
      "            US       0.89      0.97      0.93     11703\n",
      "       Ukraine       0.00      0.00      0.00         3\n",
      "       Uruguay       0.67      0.36      0.47        22\n",
      "\n",
      "      accuracy                           0.85     26370\n",
      "     macro avg       0.53      0.33      0.38     26370\n",
      "  weighted avg       0.84      0.85      0.84     26370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predictedsb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER WITH TFIDVECTORIZER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532802427000379"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with TdfidVectorizer\n",
    "pipelinesb3 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    \n",
    "    ('cls', RandomForestClassifier(n_estimators=200, n_jobs = 2))\n",
    "])\n",
    "pipelinesb3.fit(X_train1, y_train1)\n",
    "predictedsb3 = pipelinesb3.predict(X_test1)\n",
    "pipelinesb3.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NATIVE BAYES, COUNTVECTORIZER AND TFDFVECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7284034888130452"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB with CountVectorizer\n",
    "pipelinebn4 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True,\n",
    "                             ngram_range = (1,1), strip_accents='unicode')),\n",
    "    ('cls', MultinomialNB())\n",
    "])\n",
    "pipelinebn4.fit(X_train1, y_train1)\n",
    "predictedbn4 = pipelinebn4.predict(X_test1)\n",
    "pipelinebn4.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As happened with all the countries the best accuray is in Logistic Regression model with Ridge regularization.\n",
    "\n",
    "With Random Forest I got higher accuracy than with Naives Bayes but the difference is not huge.\n",
    "\n",
    "The best score is when the target has been reducing. The same what happend in the small data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS\n",
    "\n",
    "- Logistic Regression with CountVectoriazer is the best model when the target is the country. In the small dataset works better with Ridge Regularization in all the countries. However Lasso Regularization performs better in the big dataset. \n",
    "\n",
    "- All the models performs better than the baseline. \n",
    "\n",
    "- The best accuracy is the small data set with reduction of the number of countries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
